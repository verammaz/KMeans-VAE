{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verammaz/KMeans-VAE/blob/main/run_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# VAE Training Pipeline on Google Colab\n",
        "\n",
        "This notebook provides a complete workflow for:\n",
        "1. Setting up the environment\n",
        "2. Generating synthetic datasets (Gaussian & Bernoulli)\n",
        "3. Training a Variational Autoencoder (VAE)\n",
        "4. Analyzing and visualizing results\n",
        "\n",
        "**Runtime:** GPU recommended for faster training (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üì¶ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "fvLrbXCciexp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_packages",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f81400-c5dd-4524-a00f-d4f6a1027343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "! pip install -q torch torchvision tqdm matplotlib wandb\n",
        "\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "check_gpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbab87fd-c9ea-4eda-eaa4-aa9d0303a7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "CUDA version: 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check available device\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_code"
      },
      "source": [
        "## Clone GitHub Repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "clone_repo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada9ae9f-8774-4f49-a6b1-800f64b4410c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KMeans-VAE'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 2 (delta 0), pack-reused 49 (from 4)\u001b[K\n",
            "Receiving objects: 100% (52/52), 127.01 MiB | 32.53 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/KMeans-VAE\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/verammaz/KMeans-VAE.git\n",
        "%cd KMeans-VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wandb_setup"
      },
      "source": [
        "## W&B Setup (Optional)\n",
        "\n",
        "If you want to log experiments to Weights & Biases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wandb_login",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "collapsed": true,
        "outputId": "77d44d33-0790-4791-c8e1-072cecd22c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvmm2146\u001b[0m (\u001b[33mvmm2146-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B configured!\n"
          ]
        }
      ],
      "source": [
        "USE_WANDB = True  # Set to True if you want W&B logging\n",
        "\n",
        "if USE_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    print(\"W&B configured!\")\n",
        "else:\n",
        "    print(\"W&B logging disabled. Set USE_WANDB=True to enable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_gen_section"
      },
      "source": [
        "## Step 1: Generate Synthetic Datasets\n",
        "\n",
        "Generate both Gaussian and Bernoulli mixture datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "generate_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090db9cc-738e-4856-c3fa-2fc69591be70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-dataset per-component counts: [102475, 102475, 102475, 102475, 102475] (dims=64)\n",
            "Wrote ./data_set/gaussian_raw  (~127.05 MB)\n",
            "Wrote ./data_set/bernoulli_raw   (~127.05 MB)\n",
            "Total on disk ‚âà 254.10 MB (target 256.00 MB)\n"
          ]
        }
      ],
      "source": [
        "# Generate datasets\n",
        "! python data/make_datasets.py \\\n",
        "    --k 5 \\\n",
        "    --dims 64 \\\n",
        "    --target-mb 256 \\\n",
        "    --seed 42 \\\n",
        "    --outroot ./data_set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "check_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c27c9b-af56-474e-e97c-5f95ab494b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "gaussian_raw:\n",
            "  Type: gaussian\n",
            "  Classes: 5\n",
            "  Dimensions: 64\n",
            "  Samples per class: [102475, 102475, 102475, 102475, 102475]\n",
            "\n",
            "bernoulli_raw:\n",
            "  Type: bernoulli\n",
            "  Classes: 5\n",
            "  Dimensions: 64\n",
            "  Samples per class: [102475, 102475, 102475, 102475, 102475]\n"
          ]
        }
      ],
      "source": [
        "# Verify data generation\n",
        "import os\n",
        "import json\n",
        "\n",
        "for dataset in ['gaussian_raw', 'bernoulli_raw']:\n",
        "    path = f'./data_set/{dataset}'\n",
        "    if os.path.exists(path):\n",
        "        with open(os.path.join(path, 'metadata.json')) as f:\n",
        "            meta = json.load(f)\n",
        "        print(f\"\\n{dataset}:\")\n",
        "        print(f\"  Type: {meta['type']}\")\n",
        "        print(f\"  Classes: {meta['k']}\")\n",
        "        print(f\"  Dimensions: {meta['dims']}\")\n",
        "        print(f\"  Samples per class: {meta['n_per']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_section"
      },
      "source": [
        "## Step 2: Train VAE\n",
        "\n",
        "Choose your configuration and train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "### Configuration Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "config_params",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9823764-2147-4278-ef17-24d432d62455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  dataset: gaussian\n",
            "  latent_dim: 10\n",
            "  hidden_dims: [128, 64]\n",
            "  kl_beta: 1.0\n",
            "  activation: LeakyReLU\n",
            "  epochs: 1\n",
            "  batch_size: 128\n",
            "  lr: 0.0003\n",
            "  optimizer: adam\n",
            "  seed: 3407\n",
            "  device: auto\n",
            "  use_wandb: True\n",
            "  wandb_project: vae-colab-experiments\n",
            "  wandb_name: None\n"
          ]
        }
      ],
      "source": [
        "# Training configuration\n",
        "CONFIG = {\n",
        "    # Dataset\n",
        "    'dataset': 'gaussian',  # 'gaussian' or 'bernoulli'\n",
        "\n",
        "    # Model architecture\n",
        "    'latent_dim': 10,\n",
        "    'hidden_dims': [128, 64],\n",
        "    'kl_beta': 1.0,  # 1.0 = standard VAE, >1.0 = beta-VAE\n",
        "    'activation': 'LeakyReLU',\n",
        "\n",
        "    # Training\n",
        "    'epochs': 1,\n",
        "    'batch_size': 128,\n",
        "    'lr': 3e-4,\n",
        "    'optimizer': 'adam',\n",
        "\n",
        "    # System\n",
        "    'seed': 3407,\n",
        "    'device': 'auto',  # 'auto', 'cuda', 'cpu'\n",
        "\n",
        "    # W&B (if enabled)\n",
        "    'use_wandb': USE_WANDB,\n",
        "    'wandb_project': 'vae-colab-experiments',\n",
        "    'wandb_name': None,  # Auto-generated if None\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_quick"
      },
      "source": [
        "### Quick Training Presets\n",
        "\n",
        "Uncomment one to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "presets"
      },
      "outputs": [],
      "source": [
        "# Preset 1: Quick test (fast, for debugging)\n",
        "# CONFIG.update({'epochs': 10, 'latent_dim': 5, 'hidden_dims': [64, 32]})\n",
        "\n",
        "# Preset 2: Standard VAE\n",
        "# CONFIG.update({'epochs': 50, 'latent_dim': 10, 'kl_beta': 1.0})\n",
        "\n",
        "# Preset 3: Beta-VAE (disentanglement)\n",
        "# CONFIG.update({'epochs': 100, 'latent_dim': 20, 'kl_beta': 4.0})\n",
        "\n",
        "# Preset 4: High capacity\n",
        "# CONFIG.update({'epochs': 100, 'latent_dim': 20, 'hidden_dims': [256, 128, 64]})\n",
        "\n",
        "print(\"Using configuration:\", CONFIG['dataset'], \"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_command"
      },
      "source": [
        "### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "train_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83ee756-335d-4036-834a-376a38eeee31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training command:\n",
            "\n",
            "python -m vae.main     --data.data_dir=data_set/gaussian_raw     --model.latent_dim=10     --model.hidden_dims=[128,64]     --model.kl_beta=1.0     --model.activation=LeakyReLU     --trainer.epochs=1     --trainer.batch_size=128     --trainer.lr=0.0003     --trainer.optimizer=adam     --trainer.device=auto     --system.seed=3407      --wandb.enabled=True     --wandb.project=vae-colab-experiments\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "\n",
            "command line overwriting config attribute data.data_dir with data_set/gaussian_raw\n",
            "command line overwriting config attribute model.latent_dim with 10\n",
            "command line overwriting config attribute model.hidden_dims with [128, 64]\n",
            "command line overwriting config attribute model.kl_beta with 1.0\n",
            "command line overwriting config attribute model.activation with LeakyReLU\n",
            "command line overwriting config attribute trainer.epochs with 1\n",
            "command line overwriting config attribute trainer.batch_size with 128\n",
            "command line overwriting config attribute trainer.lr with 0.0003\n",
            "command line overwriting config attribute trainer.optimizer with adam\n",
            "command line overwriting config attribute trainer.device with auto\n",
            "command line overwriting config attribute system.seed with 3407\n",
            "command line overwriting config attribute wandb.enabled with True\n",
            "command line overwriting config attribute wandb.project with vae-colab-experiments\n",
            "Configuration:\n",
            "system:\n",
            "    seed: 3407\n",
            "    out_dir: ./out\n",
            "wandb:\n",
            "    enabled: True\n",
            "    project: vae-colab-experiments\n",
            "    entity: None\n",
            "    name: None\n",
            "    tags: []\n",
            "    notes: \n",
            "    log_freq: 10\n",
            "data:\n",
            "    data_dir: data_set/gaussian_raw\n",
            "model:\n",
            "    name: vae\n",
            "    latent_dim: 10\n",
            "    hidden_dims: [128, 64]\n",
            "    likelihood: gaussian\n",
            "    kl_beta: 1.0\n",
            "    seed: 42\n",
            "    activation: LeakyReLU\n",
            "trainer:\n",
            "    device: auto\n",
            "    num_workers: 4\n",
            "    batch_size: 128\n",
            "    lr: 0.0003\n",
            "    epochs: 1\n",
            "    optimizer: adam\n",
            "    weight_decay: 0.0\n",
            "    beta1: 0.9\n",
            "    beta2: 0.999\n",
            "    eps: 1e-08\n",
            "    grad_norm_clip: 1.0\n",
            "\n",
            "\n",
            "Loading dataset from data_set/gaussian_raw\n",
            "Train set: 435520 samples, 64 features\n",
            "Test set:  76855 samples\n",
            "Classes:   5\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvmm2146\u001b[0m (\u001b[33mvmm2146-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/KMeans-VAE/wandb/run-20251016_155504-8d4oukm8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvae_gaus_i64_k5_z10_beta1.0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vmm2146-columbia-university/vae-colab-experiments\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vmm2146-columbia-university/vae-colab-experiments/runs/8d4oukm8\u001b[0m\n",
            "W&B logging enabled: https://wandb.ai/vmm2146-columbia-university/vae-colab-experiments/runs/8d4oukm8\n",
            "\n",
            "Creating VAE model:\n",
            "  Input dim:    64\n",
            "  Latent dim:   10\n",
            "  Hidden dims:  [128, 64]\n",
            "  Likelihood:   gaussian\n",
            "  Beta (KL):    1.0\n",
            "  Activation:   LeakyReLU\n",
            "\n",
            "Training on device: cuda\n",
            "Starting training...\n",
            "============================================================\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/1 | Train Loss: 19.6630 (Recon: 14.3020, KL: 5.3610)\n",
            "\n",
            "Training completed!\n",
            "\n",
            "============================================================\n",
            "Test Set Evaluation\n",
            "============================================================\n",
            "Test Loss:        17.7313\n",
            "  Reconstruction: 13.1203\n",
            "  KL Divergence:  4.6111\n",
            "\n",
            "Saved final model to ./out/vae_gaus_i64_k5_z10_beta1.0/model.pt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m updating run metadata (1.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test/kl ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test/loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/recon ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train/kl ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train/loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/recon ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    final_test_kl 4.61105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  final_test_loss 17.73132\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: final_test_recon 13.12027\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test/kl 4.61105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test/loss 17.73132\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       test/recon 13.12027\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/kl 5.36098\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/loss 19.66297\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/recon 14.30199\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mvae_gaus_i64_k5_z10_beta1.0\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/vmm2146-columbia-university/vae-colab-experiments/runs/8d4oukm8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/vmm2146-columbia-university/vae-colab-experiments\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251016_155504-8d4oukm8/logs\u001b[0m\n",
            "W&B run finished successfully!\n"
          ]
        }
      ],
      "source": [
        "# Build command line arguments\n",
        "data_dir = f\"data_set/{CONFIG['dataset']}_raw\"\n",
        "hidden_dims_str = str(CONFIG['hidden_dims']).replace(' ', '')\n",
        "\n",
        "cmd = f\"\"\"\n",
        "python -m vae.main \\\n",
        "    --data.data_dir={data_dir} \\\n",
        "    --model.latent_dim={CONFIG['latent_dim']} \\\n",
        "    --model.hidden_dims={hidden_dims_str} \\\n",
        "    --model.kl_beta={CONFIG['kl_beta']} \\\n",
        "    --model.activation={CONFIG['activation']} \\\n",
        "    --trainer.epochs={CONFIG['epochs']} \\\n",
        "    --trainer.batch_size={CONFIG['batch_size']} \\\n",
        "    --trainer.lr={CONFIG['lr']} \\\n",
        "    --trainer.optimizer={CONFIG['optimizer']} \\\n",
        "    --trainer.device={CONFIG['device']} \\\n",
        "    --system.seed={CONFIG['seed']} \\\n",
        "\"\"\"\n",
        "\n",
        "MODEL_NAME = f\"vae_{CONFIG['dataset']}_z{CONFIG['latent_dim']}_beta{CONFIG['kl_beta']}\"\n",
        "\n",
        "# Add W&B flags if enabled\n",
        "if CONFIG['use_wandb']:\n",
        "    cmd += f\" \\\n",
        "    --wandb.enabled=True \\\n",
        "    --wandb.project={CONFIG['wandb_project']}\"\n",
        "    if CONFIG['wandb_name']:\n",
        "        cmd += f\" \\\n",
        "    --wandb.name={CONFIG['wandb_name']}\"\n",
        "\n",
        "print(\"Training command:\")\n",
        "print(cmd)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Run training\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_section"
      },
      "source": [
        "## Step 3: Analyze Results\n",
        "\n",
        "Load the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "load_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd80d755-6b01-4d85-db6a-f0d36687f966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model configuration:\n",
            "  Latent dim: 10\n",
            "  Hidden dims: [128, 64]\n",
            "  Beta: 1.0\n",
            "\n",
            "Test statistics:\n",
            "  loss: 17.7313\n",
            "  recon: 13.1203\n",
            "  kl: 4.6111\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from vae.model import VAE\n",
        "from data.data_io import load_and_split\n",
        "\n",
        "# Load trained model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "checkpoint = torch.load(os.path.join('./out', 'vae_gaus_i64_k5_z10_beta1.0/model.pt'), map_location=device)\n",
        "config = checkpoint['config']\n",
        "\n",
        "print(\"Model configuration:\")\n",
        "print(f\"  Latent dim: {config['model']['latent_dim']}\")\n",
        "print(f\"  Hidden dims: {config['model']['hidden_dims']}\")\n",
        "print(f\"  Beta: {config['model']['kl_beta']}\")\n",
        "print(f\"\\nTest statistics:\")\n",
        "for k, v in checkpoint['test_stats'].items():\n",
        "    print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "recreate_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271135ff-7d92-46d0-e255-fe9b07cc74e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Recreate model\n",
        "model_config = config['model']\n",
        "input_dim = checkpoint['model_state_dict']['mean.weight'].shape[1]\n",
        "\n",
        "model = VAE(\n",
        "    input_dim=input_dim,\n",
        "    latent_dim=model_config['latent_dim'],\n",
        "    hidden_dims=model_config['hidden_dims'],\n",
        "    likelihood=model_config['likelihood'],\n",
        "    beta=model_config['kl_beta'],\n",
        "    activation=model_config.get('activation', 'LeakyReLU')\n",
        ")\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "load_test_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ed20d9-cdca-4d3b-c682-f65c891aeb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: 76860 samples, 64 features\n"
          ]
        }
      ],
      "source": [
        "# Load test data\n",
        "data_dir = config['data']['data_dir']\n",
        "data = load_and_split(data_dir, normalize=True)\n",
        "\n",
        "X_test = torch.tensor(data['X_test'], dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(data['y_test'], dtype=torch.long)\n",
        "\n",
        "print(f\"Test set: {X_test.shape[0]} samples, {X_test.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## Download Results\n",
        "\n",
        "Download trained model and checkpoints to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# Zip the output directory\n",
        "!zip -r vae_results.zip out/\n",
        "\n",
        "print(\"Results zipped!\")\n",
        "print(\"Download 'vae_results.zip' from the file browser on the left.\")\n",
        "\n",
        "# Or use Google Drive (if mounted)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r out/ /content/drive/MyDrive/vae/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_section"
      },
      "source": [
        "## Experiment: Compare Different Beta Values\n",
        "\n",
        "Run a quick sweep to see the effect of different beta values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtULqONGli_Q"
      },
      "outputs": [],
      "source": [
        "# Sweep different beta values\n",
        "beta_values = [0.5, 1.0, 2.0, 4.0]\n",
        "\n",
        "for beta in beta_values:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with beta = {beta}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    cmd = f\"\"\"python main.py \\\\\n",
        "        --data.data_dir=./data_set/gaussian_raw \\\\\n",
        "        --model.kl_beta={beta} \\\\\n",
        "        --model.latent_dim=10 \\\\\n",
        "        --trainer.epochs=30 \\\\\n",
        "        --trainer.batch_size=128 \\\\\n",
        "        --system.out_dir=./out/vae_beta_{beta}\"\"\"\n",
        "\n",
        "    if USE_WANDB:\n",
        "        cmd += f\" \\\\\\n        --wandb.enabled=True \\\\\\n        --wandb.name=beta_{beta}\"\n",
        "\n",
        "    # Execute command\n",
        "    import os\n",
        "    os.system(cmd.replace('\\\\\\n', ' '))\n",
        "\n",
        "print(\"\\nBeta sweep complete! Check out/vae_beta_* directories for results.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}